# AE-MSR
In this paper, we propose a two-stage speech recognition model. In the first stage, the target voice is separated from background noises with help from the corresponding visual information of lip movements, making the model â€˜listen' clearly. At the second stage, the audio modality combines visual modality again to better understand the speech by a MSR sub-network, further improving the recognition rate.
## Requirement
  Tensorflow 1.12.0.<br> 
  CUDA 9.0 or higher.<br> 
  MATLAB (optionally)
